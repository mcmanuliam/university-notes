#ui 

- Providing "descriptive statistics" of quantitative data is the bare minimum in quantitative contexts (not always needed!)
	- Average, distribution, standard deviation

- Helps us to
	- make claims 
	- infer causal relationships 
	- hypothesis test

# Measurement Scales

- **Nomial / Categorical**
	- e.g. tags for classes
	- Labels or names
	- These could be numbers; but can't do computations with them.

- **Ordinal**
	- Can put the values in a ranking, but not equally spaced
	- e.g. Ordered list of favourite films
	- Can do < or > comparisons but not valid to calculate means.

- **Interval**
	- e.g. Scale of 1 to 10
	- Equal distances between adjacent values, but no absolute zero

- **Ratio**
	- Do have absolute zero 
	- e.g. time, distance, counts of events
	- Support many calculations 
	- add, divide, mean, standard deviation
	
![[Screenshot 2025-04-14 at 11.02.41.png]]
# Population and Sample

- Limited access to Population (all)
- We use of Samples (subset) → Proxy for Population 
- Task Measurement 
- Estimation → The average result from the sample is used to estimate the average result for the entire user population

# Descriptive Statistics

- Measures of Central Tendency: Mean, Median, and Mode 
	- The mean is simple to calculate, but also provide little (or potentially misleading) information
	- The median may differ significantly from the mean, and this can insight into the "shape" of the data

- Standard Deviation describes the spread of the data

## Mean and Mode

- Mean (X) = $(5+5+3+3)/4 = 4$
- Mean(Y) = $(20+22+40+42)/4 = 31$
- Modes? → No single mode as no repeating numbers!

![[Screenshot 2025-04-14 at 10.33.17.png]]

## Standard Deviation

Measure of how spread-out numbers are in a dataset. • It tells you how much the numbers vary from the average (mean).

1. Find mean 
2. Find difference of each value from mean 
3. Square differences 
4. Add up all squared differences 
5. Average 
6. Take square root.

- Standard deviation? 
	- Spread of data 
	- Consistency

- Normal distribution?
	- Bell shaped, symmetrical curve
	- Common in nature!

- Z-Score?
	- how many sample values fall within n std devs of mean
	- 0 → value is at mean 
	- 0 → value is above mean
	- ![[Screenshot 2025-04-14 at 10.35.45.png]]

## Data Skew & Central Limit Theorem

![[Screenshot 2025-04-14 at 10.36.21.png]]

If you take many random samples from any population and calculate the mean of each sample, the distribution will be normal (bellshaped, approximately), regardless of the original population's distribution.

- Technically: As the sample size approaches infinity… 
- For us: > 30 (even smaller for interval data) 
- Even applies to binary data! Example: 
	- Completion (y/n) 
	- Completion rate

- Many statistical hypothesis tests (e.g. t-test) assume normal distribution of data
	- If data non-normally distributed (e.g. skewed), will these tests be invalid?
	- If sample size is large enough, CLT tells us that the distribution of sample means approximate a normal distribution 
	- And so, we can use these hypothesis tests!

# Standard Error

For the sake of this example imagine we weighed 5 mice.

![[Screenshot 2025-04-14 at 10.39.26.png]]

Now imagine we done the same experiment 5 separate times, using different mice each time.

![[Screenshot 2025-04-14 at 10.40.05.png]]

![[Screenshot 2025-04-14 at 10.40.22.png]]

![[Screenshot 2025-04-14 at 10.40.31.png]]

![[Screenshot 2025-04-14 at 10.40.47.png]]

- But we don't want to 
	- run multiple experiments 
	- take multiple samples!


- How we model standard error

## Why Bother? Sample vs. Population!

- Standard deviation is about variability within a single dataset → sample 
- Standard error is about precision of the sample mean as an estimate → population

# T-distribution

- We cannot always know about distributions, means, SD and so on of population, only our sample
- Student's t-distribution, t-scores rather than z-scores

![[Screenshot 2025-04-14 at 10.42.45.png]]

# Hypothesis Testing

 - Hypothesis testing to prove something measurable about a system.
 - Start with key question, e.g. is A better than B? 
 - Consider how you will measure "better", 
	 - Does using A result in faster completion times than B?
	 - Does using A lead to less errors than B? 

- Phrase this as a **falsifiable** statement,
	- e.g. There is no difference between A and B. (null hypothesis or 𝐻0) 
	- **Goal: Rejecting the null hypothesis → there's a difference**

- We look for sufficient evidence (instead of definitive proof) 
	- Science changes, often safer to say evidence rather than proof

- Evidence to reject H
- We use statistical test for those: there are lots!
- What are stats tests testing and telling you?
	- How likely is it that two samples are from the same distribution
	- How confident are we that they're different? → confidence interval 
	- By how much are they different? → p-value

- Consider an example comparing a mouse to a trackpad
	- Null hypothesis 𝐻0: There is no difference between user performance in using these two input devices for an object selection task.

- Collect data about user performance for both devices.
- Perform hypothesis testing.
	- Reject H0 → there is probably a difference
	- Fail to reject H0 → there's probably no difference (but we don't know)

Now how do we test this?

## T-Tests

- There are many different tests. One of the most common is t-test
- Assumptions it makes:
	- Data follows a normal distribution 
	- Data drawn from interval/ratio data

- What it does:
	- Compares sample means 
	- Computes our p-value 
		- The higher the P value the higher the chance that the difference in our data is random.
	
	- Computes confidence interval (CI)

> Value between 0 and 1 (percentage) 
> Lots of confusion about this! Careful! 
> 
> "How likely it is to get this results if the 𝐻0 is true." or "How likely is it that difference is by chance?" or "Low p means the null hypothesis unlikely to be true."
> 
> In HCI: if < 0.05, less than 5% chance that difference is by chance → we reject 𝐻0.
## Errors

- Remember: 𝐻0 = no difference 
- p: Likelihood that difference is by chance. 
- **Type 1**: False Positive Acting on something that is not real. 
- **Type 2:** False Negative Missing something that is real.

# Correlations

***YOU ONLY NEED TO KNOW WHAT THESE MEAN, NOT HOW TO CALCULATE THEM***
## Relationships between Two Variables

- Correlation coefficient (Pearson's r) → measures statistical relationship between two variables: X and Y
- Measures relationship strength and direction (positive or negative).

![[Screenshot 2025-04-14 at 10.59.47.png]]

## Comparing Correlation Plots

- Correlation coefficient (r) is between -1 to 1.
- 1 means perfect positive correlation, -1 means perfect negative correlation, and 0 means no correlation.

![[Screenshot 2025-04-14 at 11.00.52.png]]

![[Screenshot 2025-04-14 at 11.01.15.png]]

# Statistics Task

| Participant ID | User Satisfaction Rating | User Experience UX |
| -------------- | ------------------------ | ------------------ |
| 1              | 5                        | 10                 |
| 2              | 5                        | 8                  |
| 3              | 4                        | 9                  |
| 4              | 2                        | 8                  |
| 5              | 2                        | 4                  |

- Mode: No mode because there's no single number picked the most.

## User Satisfaction Rating

- Median: 3.5
- Mean: 3.6
- Standard Deviant: 

$$= \sqrt\frac{(5 - 3.6)^2+(5 - 3.6)^2+(4 - 3.6)^2+(2 - 3.6)^2+(2 - 3.6)^2}{5}$$
$$= \sqrt\frac{9.2}{5}$$
$$=1.36$$


$$\text{Sum of product differences from Mean UX}=(10-7.9)+(8-7.9)+(9-7.9)+(8-7.9)+(7.9-4)$$
$$\text{Sum of product differences from Mean UX}=7.3$$


$$\text{Sum of product differences from Mean Satisfaction}=(5-3.6)+(5-3.6)+(4-3.6)+(3.6-2)+(3.6-2)$$
$$\text{Sum of product differences from Mean Satisfaction}=6.4$$

$$\text{Sum of squares for Satisfaction} = 5^2 + 5^2 + 4^2 + 2^2 + 2^2$$
$$\text{Sum of squares for Satisfaction} = 74$$

$$\text{Sum of squares for UX} = 10^2 + 8^2 + 9^2 + 8^2 + 4^2$$
$$\text{Sum of squares for UX} = 100 + 64 + 81 + 64 + 16 = 325$$

$$r(X, Y) = \frac{7.3 * 6.4}{\sqrt{74*325}}$$
$$r(X, Y) = \frac{46.72}{155} = 0.3$$
