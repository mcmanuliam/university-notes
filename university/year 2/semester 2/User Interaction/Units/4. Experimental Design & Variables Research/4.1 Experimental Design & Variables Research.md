#ui
# The Importance of Experimental Design

![[Screenshot 2025-04-04 at 10.13.46.png]]

# Method / Methodology

Methodology is the way an experiment is designed and carried out. Sound methodology is critical to understand what is really going on (signal) in a noisy and messy world (noise):

![[Screenshot 2025-04-04 at 10.15.09.png]]

This is quiet a nice metaphor for it, when we gather data and carry out experiments you'll notice there's lots of external factors which effect the validity of the data.

# Validity

- Internal Validity
	- Is the test itself valid for what we are looking for.
	
- External Validity
	- Can this be generalised across a larger dataset.
	- Imagine we measure the height of all people in the class, it wouldn't be valid to take that average and say that the average height of the world is that since it's only a small dataset with a bunch of bias.

- Often tension between interval vs external: one at expense of other?

# Independent Variables (Also Called factors)

Experiments with independent variables are often called factorial experiments. These can be naturally occurring or directly created by the experimenter.

**Characteristics**:

e.g. of computer interface - input device, feedback modality, display size.
e.g. of participants - gender, handedness, expertise OR **Circumstances** 
e.g. background noise, room lighting.

**Levels**:

Each test condition, e.g. `mouse` and `trackpad` are levels of independent variable.

# Dependent Variables

In HCI the Dependant Variables is a often a measured human behaviour. The measurement *depends* on what the participant does.

**Any observable, measurable behaviour can be a DV:**
e.g. typing speed, eye movements, `negative facial expressions` etc.

You can be quite creative here to get the measurement that tells you the most about the impact of the independent variable.

# Effect Numbers

You can have (and will often want) more than one Internal Variables and Dependent Variables in a study. However it is important to limit these as the more Internal Variables you have the more comparisons there are.

![[Screenshot 2025-04-04 at 10.29.44.png]]

Increasing IVs quickly accelerate your number of observed effects, so limit to 1 – 3.

# Control Variables

These are not under investigation (i.e. are not Internal Variables) but they might influence participant behaviour (Dependent Variables)

e.g. keyboard angle, chair height, display size

Experimenters control these variables to prevent their influence by setting up their study in a controlled environment and recruiting with strict inclusion / exclusion criteria.

e.g. Right handed only, Experienced users only.

Increases internal validity but reduces external.

# Random Variables

Instead of attempting to control for everything it is sometimes better to allow some variables to vary randomly in order to generalise results.

e.g. height, hand size, social disposition.

Each study will require judgement about the trade off between control and allowing random variation.

1. In a study investigating the acceptability of two in-car interaction techniques for the general population.

2. In a study comparing the user of a VR headset in a moving vehicle with different VR conditions to mediate sickness level.

# Confounding Variables

In some cases a circumstance or condition will change systematically with the independent variable. Such variables are confounding because they prevent the possibility of a cause and effect relationship being inferred from the results. So they need to be controlled for.

A good example was if I was doing an experiment on reaction time but halfway through I turn off the lights, I've introduced something that will massively change the values.

**This is a central skill needed in experimental design.**

Prior experience will almost definitely confound our attempts to find the best keyboard…

![[Screenshot 2025-04-04 at 10.37.36.png]]

# Participants

In order to correctly assume that research results apply to people other than those recruited you must:

- **Recruit people from the population you want to investigate.**
- **Recruit a sufficient number of participants so you can generalise**

A good sample size to go for is 1/6th of a total dataset, if it's obviously biased then, take this as an example:

![[Screenshot 2025-04-04 at 10.41.55.png]]

There's more red tops than blue tops.

## Recruitment

Ideally we would like to select people at random from a population:

![[Screenshot 2025-04-04 at 10.43.28.png]]

But sometimes that isn't as easy so instead we go by connivence sampling, if I'm doing a study on people my age, I'll just ask the people I know since it's convenient but that's not the best.

![[Screenshot 2025-04-04 at 10.44.48.png]]

**How many people should you recruit?**

- **More is better:** However there is a balance between representing the population and practical, and sometimes ethical considerations.

- **Practical**: Not much time to recruit (e.g. in student project), population difficult to access, more testing delays product going to market, over gathering could make it a pain to work through the data.

- **Ethical**: Study puts participants under burden; continuing study beyond necessary delays useful intervention or technique that can improve access.

**Central Limit Theorem:**

- As sample size increases to > 30 becomes approximately normally distributed.

- **This means that, if you are measuring abilities that are normally distributed in general population (e.g. typing accuracy on a task) then after around 30 people are recruited this will be reflected in the data.**

- Therefore there has been a rule of thumb in psychology research that 30 people is a good number

# Order Effects

In general within-subject designs are favoured in HCI due to the nature of the research – this means we need to do something about the interference between test conditions or **order effects**:

## Learning Effects

Order effects are usually a problem because of learning - people's performance on a task improves 