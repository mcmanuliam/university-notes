- [[Concurrency Beyond Threads & Limits of Scalability.pdf]]

# Intricacies of Low-Level Concurrency

A concurrent program shares all the challenges of a sequential program. i.e. **what** to compute. In other words: A correct and efficient algorithm, using appropriate data structures, must be constructed.

A concurrent program must also specify a correct and effective strategy for Coordination: i.e. how threads should cooperate.

## Concurrency Reflection

Managing concurrent threads that share state is tricky, if you use locks you must lock and unlock correctly, you must avoid the common problems of:

- Starvation
- Livelock
- Deadlock

## Some Important Coordination Aspects

**Partitioning** - determining what parts of the program should be evaluated separately.
**Placement** - determining where and when threads should be executed.
**Communication** - when and what data to send.
**Syncronisation** - ensuring threads can cooperate without interference.

# Green Threads

Language-level concurrency: a thread that is managed by a runtime library or language virtual machine (== user threads), not natively by the operating system (== kernel threads).
# User and Kernel Thread Mappings

In the end, only kernel threads run on processors so we eventually need to map these user threads to kernel threads.

![[Screenshot 2025-01-03 at 20.55.46.png]]


**Advantages** 
- Lightweight: Creating, managing, and destroying kernel threads requires time and memory (i.e. reserving each thread's stack)
- Concurrency in a language – independent of OS and hardware support for concurrency/parallelism 
- Easy-to-use concurrency (easy to have mutual exclusion, easier to reason about possible interleaving, especially with cooperative multi-tasking) 

**Disadvantage**: Mapped to a single kernel thread → can only offer concurrency, not parallelism 
- Cannot take advantage of parallel hardware 
- A single blocking user thread can block all others (if there is no preemption) 
- A user thread blocking on I/O can move all the user threads out-of-core

# Scalability

**Strong Scaling**: Fixed load, different resources
- Best case: linear scalability
- There are usually diminishing returns from some point

**Weak Scaling**: Scale resources and load proportionally
- Can we use e.g. twice as many resources to handle twice the load (with the same performance)
- Typically, this is less bounded